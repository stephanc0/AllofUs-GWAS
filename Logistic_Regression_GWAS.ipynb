{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-family:'arial';font-size:30px\"> Genomic Data Fundamentals </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02_Hail_part2_GWAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Jennifer Zhang, Francis Ratsimbazafy, Jun Qian\n",
    "\n",
    "**Contributors:** Christopher Lord, Nicole Deflaux, Kelsey Mayo, Lee Lichtenstein, *All of Us* Genomic Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With minor modifications from Stephan Cordogan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"font-size:16px\">\n",
    "Before you start running this notebook, make sure you are using a Dataproc runtime. To do so,<br>\n",
    "   <ul>\n",
    "       <li> Click on the <b>Jupyter</b> icon on the right hand side of the screen </li>\n",
    "       <li> Inside <b>Recommended environments</b>, select <b>Hail Genomics Analysis</b> which creates the computer type <b>Dataproc Cluster</b> </li>\n",
    "       <li> Select reasonable defaults for CPU, RAM, disk and numbers of workers </li>\n",
    "       <li> Click on <b>Next</b> </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cell below provides the environment information, time, and cost to run the notebook. \n",
    "\n",
    "\n",
    "- You can increase the number of workers to make this job complete faster.\n",
    "\n",
    "\n",
    "- You can also run this notebook in the background. Please refer to the notebook [Run Notebooks in the Background](https://workbench.researchallofus.org/workspaces/aou-rw-87f97daa/howtoworkwithallofusgenomicdatahailplink/notebooks/preview/05_How%20to%20Run%20Notebooks%20in%20the%20Background.ipynb) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<li> Main node: 8CPUs, 30GB RAM, 100 GB Disk</li>\n",
    "\n",
    "<li> Workers (50/50): 4CPUs, 15GB RAM, 150GB Disk</li>\n",
    "\n",
    "<li> Time and Cost: \\$16.86/h, ~8min, \\$2.24</li>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "We recommend that all users new to genomic data manipulation / analysis read this notebook to learn the basics of Hail.\n",
    "\n",
    "**The 1 min summary?** This is the second and final part of the tutorial series on Hail. \n",
    "\n",
    "In this notebook, you will learn \n",
    "- how to load the previously saved phenotype\n",
    "- how these two data types are merged into one matrix table for the GWAS modeling\n",
    "- how to use Hail to run your GWAS model \n",
    "- how to create Manhattan and QQ-plot to check your results.\n",
    "\n",
    "Before starting our analysis, we first need to import the following packages and environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:31:41.481107Z",
     "iopub.status.busy": "2024-04-19T15:31:41.480225Z",
     "iopub.status.idle": "2024-04-19T15:31:41.486288Z",
     "shell.execute_reply": "2024-04-19T15:31:41.484516Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:31:41.490973Z",
     "iopub.status.busy": "2024-04-19T15:31:41.490350Z",
     "iopub.status.idle": "2024-04-19T15:31:41.495824Z",
     "shell.execute_reply": "2024-04-19T15:31:41.494697Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend saving the workspace bucket path as a variable to read and save files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:31:41.500499Z",
     "iopub.status.busy": "2024-04-19T15:31:41.500070Z",
     "iopub.status.idle": "2024-04-19T15:31:41.510115Z",
     "shell.execute_reply": "2024-04-19T15:31:41.508570Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with genotype data with Hail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import Hail. We then need to import Bokeh, which Hail uses for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:31:41.586989Z",
     "iopub.status.busy": "2024-04-19T15:31:41.585692Z",
     "iopub.status.idle": "2024-04-19T15:31:44.506402Z",
     "shell.execute_reply": "2024-04-19T15:31:44.505343Z"
    }
   },
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "from hail.plot import show\n",
    "from bokeh.plotting import output_file, save\n",
    "import bokeh.io\n",
    "from bokeh.io import *\n",
    "from bokeh.resources import INLINE\n",
    "#bokeh.io.output_notebook(INLINE) \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *All of U*s genomic data use \"hg38\" as reference, so we set the default reference \"GRCh38\" while initializing Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:31:44.512028Z",
     "iopub.status.busy": "2024-04-19T15:31:44.510814Z",
     "iopub.status.idle": "2024-04-19T15:31:59.517502Z",
     "shell.execute_reply": "2024-04-19T15:31:59.516209Z"
    }
   },
   "outputs": [],
   "source": [
    "hl.init(default_reference = \"GRCh38\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Hail MatrixTable containing the variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *All of Us* Data and Research Center provides eight Hail MatrixTables with variants from different genome regions. In this tutorial, we use the Hail MatrixTable ClinVar variants. \n",
    "There are two versions of the Hail MatrixTable for each region: a MatrixTable with multi-allelic variants and a MatrixTable with multi-allelic variants split. We will use the latter version in this tutorial as Hail will only consider the first alternative allele in the regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options are also given for the ACAF version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:31:59.523403Z",
     "iopub.status.busy": "2024-04-19T15:31:59.523044Z",
     "iopub.status.idle": "2024-04-19T15:31:59.530240Z",
     "shell.execute_reply": "2024-04-19T15:31:59.528918Z"
    }
   },
   "outputs": [],
   "source": [
    "mt_path = os.getenv(\"WGS_CLINVAR_SPLIT_HAIL_PATH\")\n",
    "# mt_path = os.getenv(\"WGS_ACAF_THRESHOLD_SPLIT_HAIL_PATH\")\n",
    "# mt_path = os.getenv(\"WGS_ACAF_THRESHOLD_MULTI_HAIL_PATH\")\n",
    "\n",
    "mt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we will import the Hail MatrixTable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:31:59.535853Z",
     "iopub.status.busy": "2024-04-19T15:31:59.534946Z",
     "iopub.status.idle": "2024-04-19T15:32:04.524427Z",
     "shell.execute_reply": "2024-04-19T15:32:04.522864Z"
    }
   },
   "outputs": [],
   "source": [
    "mt = hl.read_matrix_table(mt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:32:04.531399Z",
     "iopub.status.busy": "2024-04-19T15:32:04.530028Z",
     "iopub.status.idle": "2024-04-19T15:32:08.894784Z",
     "shell.execute_reply": "2024-04-19T15:32:08.893542Z"
    }
   },
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "To speed up execution time and reduce costs, we will only work on a small interval of the genomic data. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify a small region within a single chromosome. See examples of how to specify genomic region intervals in the [Hail documentation](https://hail.is/docs/0.1/representation/hail.representation.Interval.html). **This part is not necessary in real genome-wide association studies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:32:08.900792Z",
     "iopub.status.busy": "2024-04-19T15:32:08.900323Z",
     "iopub.status.idle": "2024-04-19T15:32:08.906073Z",
     "shell.execute_reply": "2024-04-19T15:32:08.904811Z"
    }
   },
   "outputs": [],
   "source": [
    "test_intervals = ['chr21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:32:08.911432Z",
     "iopub.status.busy": "2024-04-19T15:32:08.910761Z",
     "iopub.status.idle": "2024-04-19T15:32:09.683332Z",
     "shell.execute_reply": "2024-04-19T15:32:09.682225Z"
    }
   },
   "outputs": [],
   "source": [
    "# mt = hl.filter_intervals(\n",
    "#     mt,\n",
    "#     [hl.parse_locus_interval(x,)\n",
    "#      for x in test_intervals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:32:09.688860Z",
     "iopub.status.busy": "2024-04-19T15:32:09.688466Z",
     "iopub.status.idle": "2024-04-19T15:32:49.978058Z",
     "shell.execute_reply": "2024-04-19T15:32:49.976897Z"
    }
   },
   "outputs": [],
   "source": [
    "# mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phenotypic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s read the pre-generated phenotypic data into a Hail table for later use. We will use the the function `import_table` in this step.\n",
    "\n",
    "In the demographics dataframe that we created and saved to the bucket earlier, each row represents data for one person ID. The same person IDs also represent the columns in the matrix table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the phenotype file from your workspace bucket, if you created one via the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:32:49.983204Z",
     "iopub.status.busy": "2024-04-19T15:32:49.982572Z",
     "iopub.status.idle": "2024-04-19T15:32:49.988652Z",
     "shell.execute_reply": "2024-04-19T15:32:49.987668Z"
    }
   },
   "outputs": [],
   "source": [
    "phenotype_filename = f'{bucket}/data/genomics_mt_phenotypes.tsv'\n",
    "phenotype_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you did not create your own phenotype file, you can uncomment the following line to read the copy available in the featured workspace bucket.\n",
    "- This is just an example phenotype file, please create your own phenotype file for a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2024-04-19T15:32:50.001516Z",
     "iopub.status.busy": "2024-04-19T15:32:50.000546Z",
     "iopub.status.idle": "2024-04-19T15:32:54.316564Z",
     "shell.execute_reply": "2024-04-19T15:32:54.315538Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phenotypes = (hl.import_table(phenotype_filename,\n",
    "                              types={'person_id':hl.tstr},\n",
    "                              impute=True,\n",
    "                              key='person_id')\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing a series of variant QC, we need to filter the Hail MatrixTable to only keep samples with phenotype values. We will use the function `semi_join_cols` to keep only samples in the pre-generated phenotype file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:32:54.321533Z",
     "iopub.status.busy": "2024-04-19T15:32:54.320615Z",
     "iopub.status.idle": "2024-04-19T15:33:35.657844Z",
     "shell.execute_reply": "2024-04-19T15:33:35.656598Z"
    }
   },
   "outputs": [],
   "source": [
    "mt = mt.semi_join_cols(phenotypes)\n",
    "#mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link phenotypic data with genomic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running a GWAS, we need to annotate the genomic data with the phenotype data. We will use the function `annotate_cols` to perform this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:33:35.663727Z",
     "iopub.status.busy": "2024-04-19T15:33:35.663308Z",
     "iopub.status.idle": "2024-04-19T15:33:35.684390Z",
     "shell.execute_reply": "2024-04-19T15:33:35.683422Z"
    }
   },
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(pheno = phenotypes[mt.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the genomic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing includes sample QC and variant QC. We will follow the protocol with subtle modification in this published paper [A tutorial on conducting genome-wide association studies: Quality control and statistical analysis]( https://onlinelibrary.wiley.com/doi/10.1002/mpr.1608): \n",
    "- inconsistencies in assigned and genetic sex of subjects (see sex discrepancy), \n",
    "- minor allele frequency (MAF), \n",
    "- deviations from Hardy–Weinberg equilibrium (HWE), \n",
    "- heterozygosity rate, \n",
    "- relatedness, \n",
    "- ethnic outliers (population stratification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below includes sample code to restrict the genetic variants to a specified range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_intervals = ['chrX:68112092-68112093','chrX:10198158-10198159','chrX:118782557-118782558'\n",
    "#  ,'chrX:79170974-79170975' ,'chrX:21843316-21843317', 'chrX:40063106-40063107', \n",
    "#                  'chrX:53434412-53434413', 'chrX:110688628-110688629', 'chrX:101259997-101259998'] \n",
    "\n",
    "# test_intervals = ['chrY:13470103-13470104']\n",
    "\n",
    "# mt = hl.filter_intervals(\n",
    "#     mt,\n",
    "#     [hl.parse_locus_interval(x,)\n",
    "#      for x in test_intervals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex discrepancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex concordance is part of the *All of Us* upstream genomic data quality control process, and all samples have passed the sex concordance check, so we do not need to perform this step here. For more details about the sex concordance check, please refer to the [All of Us Genomic Quality Report]( https://aousupporthelp.zendesk.com/hc/en-us/articles/4617899955092-All-of-Us-Beta-Release-Genomic-Quality-Report-)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relatedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *All of Us* Data and Research Center provides a list of samples to remove related samples from the full cohort. We will use the function `anti_join_cols` to perform this step. For more details about this list of related samples, please refer to the support article [How the All of Us Genomic data are organized](https://aousupporthelp.zendesk.com/hc/en-us/articles/4614687617556-How-the-All-of-Us-Genomic-data-are-organized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:33:35.690611Z",
     "iopub.status.busy": "2024-04-19T15:33:35.689900Z",
     "iopub.status.idle": "2024-04-19T15:33:35.694087Z",
     "shell.execute_reply": "2024-04-19T15:33:35.693235Z"
    }
   },
   "outputs": [],
   "source": [
    "related_samples_path = \"gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/relatedness/relatedness_flagged_samples.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:33:35.698177Z",
     "iopub.status.busy": "2024-04-19T15:33:35.697891Z",
     "iopub.status.idle": "2024-04-19T15:33:37.138215Z",
     "shell.execute_reply": "2024-04-19T15:33:37.137159Z"
    }
   },
   "outputs": [],
   "source": [
    "related_remove = hl.import_table(related_samples_path,\n",
    "                                 types={\"sample_id\":\"tstr\"},\n",
    "                                key=\"sample_id\")\n",
    "\n",
    "#related_remove.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:33:37.142758Z",
     "iopub.status.busy": "2024-04-19T15:33:37.142344Z",
     "iopub.status.idle": "2024-04-19T15:34:17.740963Z",
     "shell.execute_reply": "2024-04-19T15:34:17.739621Z"
    }
   },
   "outputs": [],
   "source": [
    "mt = mt.anti_join_cols(related_remove)\n",
    "#mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *All of Us* Data and Research Center provides genetic predicted ancestry including the principal components (PCs) for the WGS data. We will incorporate thes PCs into the Hail MatrixTable and set them as covariate to take population stratification into account during model building. We will read the ancestry table and annoate the Hail MatrixTable with the ancestry table in this step.\n",
    "\n",
    "For more information about the ancestry prediction table, please refer to this support article [How the All of Us Genomic data are organized](https://aousupporthelp.zendesk.com/hc/en-us/articles/4614687617556-How-the-All-of-Us-Genomic-data-are-organized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:34:17.745922Z",
     "iopub.status.busy": "2024-04-19T15:34:17.745281Z",
     "iopub.status.idle": "2024-04-19T15:34:17.749816Z",
     "shell.execute_reply": "2024-04-19T15:34:17.748869Z"
    }
   },
   "outputs": [],
   "source": [
    "ancestry_pred_path = \"gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/ancestry/ancestry_preds.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:34:17.753792Z",
     "iopub.status.busy": "2024-04-19T15:34:17.753239Z",
     "iopub.status.idle": "2024-04-19T15:34:21.175719Z",
     "shell.execute_reply": "2024-04-19T15:34:21.174409Z"
    }
   },
   "outputs": [],
   "source": [
    "ancestry_pred = hl.import_table(ancestry_pred_path,\n",
    "                               key=\"research_id\", \n",
    "                               impute=True, \n",
    "                               types={\"research_id\":\"tstr\",\"pca_features\":hl.tarray(hl.tfloat)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:34:21.180130Z",
     "iopub.status.busy": "2024-04-19T15:34:21.179826Z",
     "iopub.status.idle": "2024-04-19T15:34:21.201320Z",
     "shell.execute_reply": "2024-04-19T15:34:21.200415Z"
    }
   },
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(ancestry_pred = ancestry_pred[mt.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below includes code to filter the population by majority predicted ancestry.  When running a multiethnic GWAS, results can be slightly improved by analyzing each ethinity seperately and meta-analyzing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt_eur = mt.filter_cols(mt.ancestry_pred.ancestry_pred == \"eur\")\n",
    "# # mt_pheno_eur.col.describe()\n",
    "# mt_orig = mt\n",
    "# mt = mt_eur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heterozygosity rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allele Balance (AB) in the “Hard Threshold Filters” is part of the *All of Us* upstream data quality control processes. It marks all the variants that do not meet the threshold AB>=0.2 for heterozygotes as `NO_HQ_GENOTYPES` in the `filters` field. There are other criteria to flag specific variants from a callset which results in different values in the `filters` field. \n",
    "\n",
    "The MatrixTables for small regions have removed variants that don't pass the filters. For more details about the `filters` field, please please refer to this support article [How the All of Us Genomic data are organized](https://aousupporthelp.zendesk.com/hc/en-us/articles/4614687617556-How-the-All-of-Us-Genomic-data-are-organized)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor allele frequency (MAF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have removed some samples, we need to recompute common variant statistics for the variant quality control metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:34:21.206497Z",
     "iopub.status.busy": "2024-04-19T15:34:21.206190Z",
     "iopub.status.idle": "2024-04-19T15:34:21.371172Z",
     "shell.execute_reply": "2024-04-19T15:34:21.370246Z"
    }
   },
   "outputs": [],
   "source": [
    "mt = hl.variant_qc(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAF threshold should depend on your sample size; larger samples can use lower MAF thresholds. For large (N = 100,000) vs. moderate samples (N = 10,000), 0.01 and 0.05 are commonly used as MAF threshold, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:34:21.376330Z",
     "iopub.status.busy": "2024-04-19T15:34:21.375436Z",
     "iopub.status.idle": "2024-04-19T15:35:14.732035Z",
     "shell.execute_reply": "2024-04-19T15:35:14.731067Z"
    }
   },
   "outputs": [],
   "source": [
    "mt = mt.filter_rows(hl.min(mt.variant_qc.AF) > 0.05, keep = True)\n",
    "#mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deviations from Hardy–Weinberg equilibrium (HWE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 1e−10 as HWE p value threshold in the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was removed, as multi-ethnic cohorts will violate HWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:35:14.736549Z",
     "iopub.status.busy": "2024-04-19T15:35:14.736231Z",
     "iopub.status.idle": "2024-04-19T15:36:09.550213Z",
     "shell.execute_reply": "2024-04-19T15:36:09.549248Z"
    }
   },
   "outputs": [],
   "source": [
    "#mt = mt.filter_rows(mt.variant_qc.p_value_hwe > 1e-20, keep = True)\n",
    "#mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genome-Wide Association Study (GWAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been pre-processed, we are ready to move on to modeling. \n",
    "\n",
    "We will run a logistic regression with:\n",
    "- diabetes as the dependent variable; \n",
    "- n_alt_alleles from the genomic data as our independent variable X; and\n",
    "- sex at birth and ethnicity as covariates;\n",
    "- set the first three PC features as covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by putting all of the covariates in a variable. Note: the demographics data were integrated in the MatrixTable **mt** as a column field named **pheno**, PCA features were in the column field **ancestry_pred**.\n",
    "\n",
    "Please define your own covariates in real analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2024-04-19T15:36:09.555306Z",
     "iopub.status.busy": "2024-04-19T15:36:09.554674Z",
     "iopub.status.idle": "2024-04-19T15:36:09.561736Z",
     "shell.execute_reply": "2024-04-19T15:36:09.560885Z"
    }
   },
   "outputs": [],
   "source": [
    "covariates = [1.0, mt.pheno.is_male, mt.pheno.age_yrs,\n",
    "             mt.ancestry_pred.pca_features[0], \n",
    "              mt.ancestry_pred.pca_features[1], \n",
    "              mt.ancestry_pred.pca_features[2],\n",
    "              mt.ancestry_pred.pca_features[3],\n",
    "              mt.ancestry_pred.pca_features[4],\n",
    "              mt.ancestry_pred.pca_features[5],\n",
    "              mt.ancestry_pred.pca_features[6],\n",
    "              mt.ancestry_pred.pca_features[7],\n",
    "              mt.ancestry_pred.pca_features[8],\n",
    "              mt.ancestry_pred.pca_features[9],\n",
    "              mt.ancestry_pred.pca_features[10], \n",
    "              mt.ancestry_pred.pca_features[11], \n",
    "              mt.ancestry_pred.pca_features[12], \n",
    "              mt.ancestry_pred.pca_features[13],\n",
    "              mt.ancestry_pred.pca_features[14],\n",
    "              mt.ancestry_pred.pca_features[15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T15:36:09.565273Z",
     "iopub.status.busy": "2024-04-19T15:36:09.564955Z",
     "iopub.status.idle": "2024-04-19T15:37:35.227297Z",
     "shell.execute_reply": "2024-04-19T15:37:35.226028Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = hl.logistic_regression_rows(\n",
    "    test='wald',\n",
    "    y=mt.pheno.has_mt,\n",
    "    x=mt.GT.n_alt_alleles(),\n",
    "    covariates=covariates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tip:</b> If you want to check the contents of <i>log_reg</i>, you can use\n",
    "<pre>\n",
    "log_reg.describe()\n",
    "</pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the function `export` to save the GWAS results to the bucket for downstream analysis if needed. It is recommended to save large files with a `.bgz` extension to save time and space. Please check [Hail Table.export](https://hail.is/docs/0.2/hail.Table.html#hail.Table.export) for more detailes. \n",
    "\n",
    "Note that this method will export results to a text file. All values will be string in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> We first flatten the nested fields using function flatten, and then use the function `export` to save results to workspace bucket.\n",
    "\n",
    "\n",
    "<pre>\n",
    "log_reg = log_reg.flatten()\n",
    "\n",
    "log_reg_save_path = f'{bucket}/data/log_reg.tsv.bgz'\n",
    "\n",
    "log_reg.export(log_reg_save_path)\n",
    "</pre>\n",
    "To reuse them at a later time:\n",
    "<pre>\n",
    "gwas_result = hl.import_table(log_reg_save_path, types={\"locus\":hl.tlocus(reference_genome='GRCh38'),\"alleles\": hl.tarray(hl.tstr), \"beta\": hl.tfloat64, \"p_value\": hl.tfloat64, \"fit.n_iterations\": hl.tint32})\n",
    "</pre>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = log_reg.flatten()\n",
    "\n",
    "log_reg_save_path = f'{bucket}/data/log_reg.tsv.bgz'\n",
    "\n",
    "log_reg.export(log_reg_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "- [Hail Documentation](https://hail.is/docs/0.2/tutorials-landing.html) \n",
    "- [Hail tutorials](https://app.terra.bio/#workspaces/help-gatk/Hail-Notebook-Tutorials) \n",
    "- [A demo workspace for working with gnomAD data in Terra](https://terra.bio/a-demo-workspace-for-working-with-gnomad-data-in-terra/) \n",
    "    - [Hail notebook](https://app.terra.bio/#workspaces/terra-outreach/DEMO-Working-with-gnomAD)\n",
    "- [Copy files/objects to/from a bucket](https://cloud.google.com/storage/docs/gsutil/commands/cp) \n",
    "- [A tutorial on conducting genome-wide association studies: Quality control and statistical analysis]( https://onlinelibrary.wiley.com/doi/10.1002/mpr.1608) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
