{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "\n",
    "bucket = os.getenv(\"WORKSPACE_BUCKET\")\n",
    "dataset = os.getenv(\"WORKSPACE_CDR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Stephan Cordogan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document perpares a cohort of individuals for GWAS.  It includes information on the case/control status, as well as age and sex to be used as covariates.  Meniscus tears are the example disease in this notebook, and can be substituted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document uses some code from the document 02_Hail_part1_Prepare Phenotype, with Authors: Francis Ratsimbazafy, Jennifer Zhang and Contributors: Christopher Lord, Nicole Deflaux, Kelsey Mayo, Lee Lichtenstein, CH Albach.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your cohort of WGS individuals with sex and date of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mt_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        p_sex_at_birth_concept.concept_name as dragen_sex_ploidy  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id\n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                ) \n",
    "            )\"\"\"\n",
    "\n",
    "dataset_mt_df = pd.read_gbq(\n",
    "    dataset_mt_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_mt_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are 3 methods to define cases and controls within your cohort, each increasingly restrictive.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute one of the methods, ensure that the other two methods are hashtagged out and the chosen method is not.  In my experience, the more restrictive methods yield better results.  The most restrictive method requires a minimum of two separate visits, which is prescedented by Tcheandjieu et. al (linked below).  They also required a minimum of two disdinct ICD codes, which we did not find improved performance.  Closer examination of the dataset builder tool showed that many individuals with an ICD code had condition_start_datetime and condition_end_datetime on the same day.\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9419655/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method defines cases and controls identically to the dataset builder tool, using concept IDs, which are broad, overarching IDs specific to a disease. This will include all of the patients with moderately associated ICD codes present. In this instance, we use the concept ID for meniscus tears.  The code below is taken directly from the dataset builder tool, and simply used to define cases and controls- covariates need to be specified in the above cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hasmt_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                person_id \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "            WHERE\n",
    "                has_whole_genome_variant = 1 ) \n",
    "            AND cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (4035415)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_hasmt_person_df = pd.read_gbq(\n",
    "    dataset_hasmt_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "# Ensure 'person_id' is the index in dataset_hasmt_person_df\n",
    "dataset_hasmt_person_ids = set(dataset_hasmt_person_df['person_id'])\n",
    "\n",
    "# Create a new column 'has_mt' in dataset_mt_df based on the presence in dataset_hasmt_person_ids\n",
    "\n",
    "dataset_mt_df['has_mt'] = dataset_mt_df['person_id'].isin(dataset_hasmt_person_ids).astype(int)\n",
    "\n",
    "# The result is mt_final_cohort with has_mt set to 1 if person_id is in dataset_hasmt_person_df, otherwise is 0\n",
    "\n",
    "mt_final_cohort = dataset_mt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second method defines cases and controls by their ICD and SNOMED codes, systems used by doctors to code medical data.  The presence of an associated ICD code designates an individual as a case. ICD codes need to be specified in the immediately below cell.  If there is only a single code for ICD9, 10, or SNOMED, enter it twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Meniscus tears\n",
    "condition_codes_mt_icd9 = tuple(['836.0','836.1'])\n",
    "condition_codes_mt_icd10 = tuple(['S83.28', 'S83.281', 'S83.282', \n",
    "'S83.281A', 'S83.282A', 'S83.27', 'S83.289', 'S83.289A', 'S83.271',\n",
    "                                 'S83.241A', 'S83.242A', 'S83.221A', 'S83.222A', 'S83.289'])\n",
    "condition_codes_mt_SNOMED = tuple(['239720000', '302933001','302932006'])\n",
    "\n",
    "# #LATERAL\n",
    "\n",
    "# condition_codes_mt_icd9 = tuple(['836.1', '836.1'])\n",
    "# condition_codes_mt_icd10 = tuple(['S83.28', 'S83.281', 'S83.282', \n",
    "#  'S83.281A', 'S83.282A', 'S83.27', 'S83.289', 'S83.289A', 'S83.271'])\n",
    "# condition_codes_mt_SNOMED = tuple(['302933001','302933001'])\n",
    "\n",
    "# #MEDIAL\n",
    "\n",
    "# condition_codes_mt_icd9 = tuple(['836.0', '836.0'])\n",
    "# condition_codes_mt_icd10 = tuple(['S83.241A', 'S83.242A', 'S83.221A', 'S83.222A', 'S83.289'])\n",
    "# condition_codes_mt_SNOMED = tuple(['302932006','302932006'])\n",
    "\n",
    "# #GENERAL\n",
    "\n",
    "# condition_codes_mt_SNOMED = tuple(['239720000', '239720000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # This code retrieves concept ID for conditions matching those codes, defining the query\n",
    "\n",
    "# query = f\"\"\"                                \n",
    "# SELECT \n",
    "#     c.concept_id\n",
    "# FROM `{dataset}.concept` c\n",
    "# JOIN `{dataset}.condition_occurrence` co ON c.concept_id = co.condition_source_concept_id\n",
    "# WHERE (vocabulary_id='ICD9CM' AND concept_code IN {condition_codes_mt_icd9})\n",
    "#     OR (vocabulary_id='ICD10CM' AND concept_code IN {condition_codes_mt_icd10}) \n",
    "#     OR (vocabulary_id='SNOMED' AND concept_code IN {condition_codes_mt_SNOMED})\n",
    "\n",
    "# GROUP BY c.concept_name, c.concept_code,c.concept_id\n",
    "# \"\"\"\n",
    "\n",
    "# # This code executes the query\n",
    "\n",
    "# condition_concepts_mt_df  = pd.read_gbq(query, dialect = \"standard\")\n",
    "\n",
    "# # This code retrieves unique person ID from person table for those who have condition codes above and adds an indicator variable has_ocdc for them\n",
    "\n",
    "# query = f\"\"\"                                \n",
    "# SELECT person.person_id, \n",
    "#    -- Add an indicator variable.\n",
    "#     1 AS has_mt\n",
    "# FROM `{dataset}.person` person\n",
    "# WHERE\n",
    "#     person_id IN (SELECT person_id\n",
    "#                   FROM `{dataset}.condition_occurrence`\n",
    "#                   WHERE condition_source_concept_id IN {tuple(condition_concepts_mt_df['concept_id'])})\n",
    "# \"\"\"\n",
    "# mt_cohort = pd.read_gbq(query, dialect=\"standard\")\n",
    "\n",
    "# mt_final_cohort = (dataset_mt_df.merge(mt_cohort, on='person_id', how='left')\n",
    "#               .fillna(value={'has_mt': 0})\n",
    "#              )\n",
    "# mt_final_cohort['has_mt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third method defines cases and controls by their ICD and SNOMED codes, with a minimum of two instances of a code for an individual to be classified as a case. This is the most restrictive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code retrieves concept ID for conditions matching those codes, defining the query \n",
    "# # Individuals included must have 2+ instances of a code\n",
    "\n",
    "# query = f\"\"\"\n",
    "# SELECT \n",
    "#     co.person_id,\n",
    "#     c.concept_id,\n",
    "#     COUNT(DISTINCT co.condition_occurrence_id) AS occurrence_count\n",
    "# FROM `{dataset}.concept` c\n",
    "# JOIN `{dataset}.condition_occurrence` co ON c.concept_id = co.condition_source_concept_id\n",
    "# WHERE (vocabulary_id='ICD9CM' AND concept_code IN {condition_codes_mt_icd9})\n",
    "#     OR (vocabulary_id='ICD10CM' AND concept_code IN {condition_codes_mt_icd10}) \n",
    "#     OR (vocabulary_id='SNOMED' AND concept_code IN {condition_codes_mt_SNOMED})\n",
    "# GROUP BY co.person_id, c.concept_id\n",
    "# HAVING COUNT(DISTINCT co.condition_occurrence_id) > 1\n",
    "# \"\"\"\n",
    "\n",
    "# # This code executes the query\n",
    "\n",
    "# condition_concepts_mt_df = pd.read_gbq(query, dialect=\"standard\")\n",
    "\n",
    "# # This code retrieves unique person ID from person table for those who have condition codes above and adds an indicator variable has_ocdc for them\n",
    "\n",
    "# person_ids = tuple(condition_concepts_mt_df['person_id'].unique())\n",
    "\n",
    "# query = f\"\"\"\n",
    "# SELECT person.person_id, \n",
    "#    -- Add an indicator variable.\n",
    "#     1 AS has_mt\n",
    "# FROM `{dataset}.person` person\n",
    "# WHERE person_id IN {person_ids}\n",
    "# \"\"\"\n",
    "\n",
    "# mt_cohort = pd.read_gbq(query, dialect=\"standard\")\n",
    "\n",
    "# mt_final_cohort = (dataset_mt_df.merge(mt_cohort, on='person_id', how='left')\n",
    "#               .fillna(value={'has_mt': 0})\n",
    "#              )\n",
    "# mt_final_cohort['has_mt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_final_cohort.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code converts age into a continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = pd.Timestamp('now', tz='UTC')\n",
    "mt_final_cohort['age'] = current_date-mt_final_cohort.date_of_birth\n",
    "mt_final_cohort['age_yrs'] = mt_final_cohort.age/pd.Timedelta('365.25 days')\n",
    "mt_final_cohort.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demographics = pd.get_dummies(mt_final_cohort.set_index(['person_id'])).reset_index()\n",
    "demographics['has_mt'] = demographics['has_mt'].astype(int)\n",
    "demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below specifies the porportion of the total controls to be included in the GWAS.  This should be ~4x larger than your cases.  There are no consequences to a much larger control cohort other than the increased computational costs. The code below includes 2.5% of overall controls in the GWAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_has_mt_1 = demographics[demographics['has_mt'] == 1]\n",
    "df_has_mt_0 = demographics[demographics['has_mt'] == 0].sample(frac=0.025, random_state=1)\n",
    "demographics_reduced = pd.concat([df_has_mt_1, df_has_mt_0]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "females = demographics_reduced['dragen_sex_ploidy_Female'].sum()\n",
    "males = demographics_reduced['dragen_sex_ploidy_Male'].sum()\n",
    "total = len(demographics_reduced)\n",
    "print(females, males, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows in df_reduced\n",
    "num_rows = len(demographics_reduced)\n",
    "print(f\"Number of rows in df_reduced: {num_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line below removes individuals not classified as females or males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = demographics_reduced[\n",
    "    (demographics_reduced['dragen_sex_ploidy_Female'] != demographics_reduced['dragen_sex_ploidy_Male'])\n",
    "]\n",
    "\n",
    "# Select and rename the columns\n",
    "phenotypes = (filtered_data[[\"person_id\", \"has_mt\", \"dragen_sex_ploidy_Female\", \"dragen_sex_ploidy_Male\", \"age_yrs\"]]\n",
    "              .rename(columns={'dragen_sex_ploidy_Female': 'is_female', 'dragen_sex_ploidy_Male': 'is_male'})\n",
    "             )\n",
    "phenotypes['is_male'] = phenotypes['is_male'].astype(int)\n",
    "\n",
    "num_rows = len(phenotypes)\n",
    "print(f\"Number of rows in phenotypes: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes[\"person_id\"] = phenotypes[\"person_id\"].astype(str)\n",
    "    \n",
    "phenotypes.to_csv('genomics_mt_phenotypes.tsv', index=False, sep='\\t')\n",
    "\n",
    "# save phenotypes to the bucket\n",
    "!gsutil cp 'genomics_mt_phenotypes.tsv' {bucket}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes['has_mt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m ls {bucket}/data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
